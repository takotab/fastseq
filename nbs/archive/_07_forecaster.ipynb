{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecaster\n",
    "\n",
    "> Uses a trained `Model`/`Learner` to predict future samples.\n",
    "\n",
    "Mostly copied from <https://github.com/MSRDL/Deep4Cast>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from fastcore.utils import *\n",
    "from fastcore.imports import *\n",
    "from fastai.basics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Forecaster():\n",
    "    \"\"\"Handles training of a PyTorch model and can be used to generate samples\n",
    "    from approximate posterior predictive distribution.\n",
    "    Arguments:\n",
    "        * model (``torch.nn.Module``): Instance of Deep4cast :class:`models`.\n",
    "        * device (str): Device used for training (`cpu` or `cuda`).\n",
    "        * verbose (bool): Verbosity of forecaster.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 device='cpu',\n",
    "                 verbose=True):\n",
    "        self.device = device if torch.cuda.is_available() and 'cuda' in device else 'cpu'\n",
    "        self.model = model.to(device)\n",
    "        self.history = {'training': [], 'validation': []}\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def predict(self, dataloader, n_samples=100) -> np.array:\n",
    "        \"\"\"Generates predictions.\n",
    "        Arguments:\n",
    "            * dataloader (``torch.utils.data.DataLoader``): Data to make forecasts.\n",
    "            * n_samples (int): Number of forecast samples.\n",
    "        \n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            for batch in dataloader:\n",
    "                inputs = batch[0].to(self.device)\n",
    "                samples = []\n",
    "                for i in range(n_samples):\n",
    "                    y = self.model(inputs)\n",
    "#                     outputs = self.loss(**outputs).sample((1,)).cpu()\n",
    "#                     y = outputs[0]\n",
    "    \n",
    "#                     outputs = copy.deepcopy(batch)\n",
    "#                     outputs = dataloader.dataset.transform.untransform(outputs)\n",
    "                    samples.append(y[None, :])\n",
    "                samples = np.concatenate(samples, axis=0)\n",
    "                predictions.append(samples)\n",
    "            predictions = np.concatenate(predictions, axis=1)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def embed(self, dataloader, n_samples=100) -> np.array:\n",
    "        \"\"\"Generate embedding vectors.\n",
    "        Arguments:\n",
    "            * dataloader (``torch.utils.data.DataLoader``): Data to make embedding vectors.\n",
    "            * n_samples (int): Number of forecast samples.\n",
    "        \n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            for batch in dataloader:\n",
    "                inputs = batch['X'].to(self.device)\n",
    "                samples = []\n",
    "                for i in range(n_samples):\n",
    "                    outputs, __ = self.model.encode(inputs)\n",
    "                    samples.append(outputs.cpu().numpy())\n",
    "                samples = np.array(samples)\n",
    "                predictions.append(samples)\n",
    "            predictions = np.concatenate(predictions, axis=1)\n",
    "\n",
    "        return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 12\n",
    "lookback = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastseq.data.load import *\n",
    "from fastseq.data.transforms import *\n",
    "from fastai.data.all import *\n",
    "from fastseq.models.wavenet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(1000)\n",
    "lenghts = np.random.randint(10,500,100)\n",
    "data_train = [np.array([i+.5*np.sin(t[:l]),\n",
    "              t[:l]+(0.1*np.random.randn()),\n",
    "             ])\n",
    "              for i,l in enumerate(lenghts)]\n",
    "\n",
    "# print([d.shape for d in data_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_ds = TimeSeriesDataset(\n",
    "    data_train,\n",
    "    lookback,\n",
    "    horizon,\n",
    "    step=1,\n",
    "    static_covs = [1,2,2,2,2],\n",
    "    transform = ToTensor()\n",
    ")\n",
    "ts_dl = DataLoader(\n",
    "    ts_ds,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 13838, 1, 12)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "model = WaveNet(input_channels=2,\n",
    "                output_channels=1,\n",
    "                horizon=horizon,                    \n",
    "               )\n",
    "predictor = Forecaster(model)\n",
    "# predictor.predict(ts_dl, n_samples=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.external.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "Converted 02_deep4cast_m4_example.ipynb.\n",
      "Converted 03_data.load.ipynb.\n",
      "Converted 04_data.transforms.ipynb.\n",
      "Converted 05_models.wavenet.ipynb.\n",
      "Converted 06_models.dnn.ipynb.\n",
      "Converted 07_forecaster.ipynb.\n",
      "Converted 08_metrics.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env37",
   "language": "python",
   "name": "env37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
